# ğŸš€ Kafka Final Project: Real-time User Behavior Analysis

**Estudiantes:** Daniel Herrera, Alan Mendoza, Emmanuel Carmona  
**Curso:** Kafka - Unit III  
**Fecha:** Diciembre 2025

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa una arquitectura de **streaming de datos distribuida** utilizando Apache Kafka. El sistema simula el ecosistema de un E-commerce en tiempo real, generando eventos de interacciÃ³n de usuarios (vistas, carritos, compras), procesÃ¡ndolos para obtener mÃ©tricas analÃ­ticas y visualizando el flujo de datos.

El objetivo principal es demostrar la capacidad de **ingesta, procesamiento y visualizaciÃ³n** de volÃºmenes de datos concurrentes, cumpliendo con los estÃ¡ndares de modelado de informaciÃ³n y escalabilidad.

---

## ğŸ—ï¸ Arquitectura del Pipeline

El flujo de informaciÃ³n sigue el patrÃ³n **Producer-Broker-Consumer**:

* **Data Source (JSON):** CatÃ¡logos estÃ¡ticos de `products.json` y `users.json` simulan la base de datos maestra.
* **Producers (Python + Threading):** Scripts que generan eventos sintÃ©ticos. Soportan concurrencia mediante hilos para simular mÃºltiples usuarios activos simultÃ¡neamente.
* **Message Broker (Kafka):** Cluster gestionado vÃ­a Docker, encargado de recibir y distribuir los mensajes en el topic `product-events`.
* **Consumers (Analytics):** Procesamiento en tiempo real que calcula KPIs (Key Performance Indicators) como "Top Productos" y segmentaciÃ³n de usuarios.
* **VisualizaciÃ³n (Kafka UI):** Interfaz grÃ¡fica para monitoreo de offsets, particiones y flujo de mensajes.

---

## ğŸ“‚ Estructura del Proyecto

La organizaciÃ³n del cÃ³digo sigue principios de modularidad y buenas prÃ¡cticas:

```text
KafkaFinalProject/
â”œâ”€â”€ data/                   # Fuentes de datos estÃ¡ticas
â”‚   â”œâ”€â”€ products.json       # CatÃ¡logo de productos (ID, CategorÃ­a, Precio)
â”‚   â””â”€â”€ users.json          # Usuarios con segmentaciÃ³n (RegiÃ³n, Tipo)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producers/          # LÃ³gica de generaciÃ³n de eventos
â”‚   â”‚   â””â”€â”€ main_producer.py
â”‚   â”œâ”€â”€ consumers/          # LÃ³gica de procesamiento y analÃ­tica
â”‚   â”‚   â””â”€â”€ analytics_consumer.py
â”‚   â””â”€â”€ utils/              # Configuraciones compartidas
â”œâ”€â”€ docker-compose.yml      # OrquestaciÃ³n de Zookeeper, Kafka y Kafka UI
â”œâ”€â”€ .env                    # Variables de entorno (ConfiguraciÃ³n)
â”œâ”€â”€ requirements.txt        # Dependencias de Python
â””â”€â”€ README.md               # DocumentaciÃ³n
```
---
## âš™ï¸ Requisitos Previos
Docker Desktop (con Docker Compose instalado).

Python 3.8 o superior (Probado en Python 3.12+).

Git (Opcional, para control de versiones).

## ğŸš€ GuÃ­a de InstalaciÃ³n y EjecuciÃ³n
Sigue estos pasos para levantar el entorno completo en tu mÃ¡quina local.

1. ConfiguraciÃ³n del Entorno Virtual
Es necesario aislar las dependencias para evitar conflictos, especialmente con versiones modernas de Python.

# Windows (PowerShell)
python -m venv venv
.\venv\Scripts\Activate

# Instalar dependencias
pip install -r requirements.txt
2. ConfiguraciÃ³n de Variables (.env)
El proyecto utiliza variables de entorno para facilitar la configuraciÃ³n. El archivo .env incluye:

Properties

KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_PRODUCTS=product-events
KAFKA_TOPIC_USERS=user-events
KAFKA_TOPIC_PURCHASES=purchases
3. Despliegue de Infraestructura (Docker)
Levanta los contenedores de Zookeeper, Kafka Broker y Kafka UI.

docker-compose up -d
Nota: Espere unos 30 segundos hasta que los servicios estÃ©n completamente iniciados.

## â–¶ï¸ EjecuciÃ³n de la SimulaciÃ³n
Para ver el sistema en acciÃ³n, se recomienda usar dos terminales separadas.

Terminal 1: Consumer (AnalÃ­tica)
Inicie primero el consumidor para que estÃ© listo para procesar los mensajes entrantes.


# AsegÃºrese de tener el venv activado
python -m src.consumers.analytics_consumer
Se mostrarÃ¡ un dashboard en consola esperando eventos.

Terminal 2: Producer (Generador de TrÃ¡fico)
Inicie el simulador de trÃ¡fico. Este script lanzarÃ¡ 3 hilos concurrentes simulando usuarios distintos enviando datos al mismo tiempo.

# En una nueva terminal con venv activado
python -m src.producers.main_producer

## ğŸ“Š Monitoreo y VerificaciÃ³n
Dashboard en Consola
En la Terminal 1, verÃ¡ actualizaciones en tiempo real con las siguientes mÃ©tricas:

Total de eventos procesados.

Conteo por tipo de evento (view, add_to_cart, remove_from_cart).

Actividad por segmento de usuario (Premium, Standard).

Producto mÃ¡s visto/interactuado.

Kafka UI (VisualizaciÃ³n Web)
Acceda a la interfaz grÃ¡fica para verificar la creaciÃ³n de topics y la persistencia de mensajes:

## ğŸ”— URL: http://localhost:8080

Navegue a la secciÃ³n Topics.

Seleccione product-events.

Vaya a la pestaÃ±a Messages para ver el payload JSON crudo ingresando en tiempo real.

## ğŸ› ï¸ TecnologÃ­as Utilizadas
Lenguaje: Python 3.13

Streaming: Apache Kafka (Confluent Image 7.4.0)

OrquestaciÃ³n: Docker Compose

LibrerÃ­as Clave:

kafka-python-ng: Cliente Kafka compatible con versiones recientes de Python.

python-dotenv: GestiÃ³n de configuraciÃ³n.

## ğŸ“ Notas TÃ©cnicas
Compatibilidad Python: Se utiliza kafka-python-ng en lugar de la librerÃ­a estÃ¡ndar antigua para garantizar compatibilidad con Python 3.12+.

SerializaciÃ³n: Todos los mensajes se serializan en JSON UTF-8.

Concurrencia: El Producer implementa threading para simular carga real, cumpliendo con el requerimiento de la rÃºbrica sobre mÃºltiples productores simultÃ¡neos.

Proyecto desarrollado para la evaluaciÃ³n final de la Unidad III.
